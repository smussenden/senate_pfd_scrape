---
title: "Senate_pfd_scrape.rmd"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(rvest)
library(janitor)
```
```{r}
####
## Get dataframe of links to loop through
####
# Define html
filings_table_url <- "https://sec.report/Senate-Stock-Disclosures/Filings"

# Read table in
filings_table <- filings_table_url %>%
  read_html() %>%
  html_table() 

# Extraxct from list
filings_table <- filings_table[[1]]

# Create urls to loop through
filings_table <- filings_table %>%
  clean_names() %>%
  filter(title == "Annual Report for CY 2020" & shares_held == "Annual") %>%
  mutate(filed_date = str_sub(filed_date_report_id,start=1L, end=10L)) %>%
  mutate(report_id = str_sub(filed_date_report_id,start=12L, end=-1L)) %>%
  select(filed_date,report_id,everything(),-filed_date_report_id) %>%
  mutate(senator = str_remove_all(reported_by,"[[:punct:]]")) %>%
  separate(senator,into=c("a","b","c","d")) %>%
  mutate(first_name = case_when(
    a == "Ladda" ~ paste0(a,"+",b),
    a == "W" ~ paste0(a,"+",b),
    a == "A" ~ paste0(a,"+",b),
    str_length(b) > 1 ~ a,
    TRUE ~ paste0(a,"+",b)
  )) %>%
  mutate(last_name = case_when(
    a == "Ladda" ~ c,
    a == "W" ~ c,
    c == "III" ~ paste0(b,"+",c),
    is.na(c) ~ b,
    !is.na(d) ~ paste0(c,"+",d),
    str_length(b) == 1 ~ c,
    TRUE ~ d
  )) %>%
  mutate(report_url = paste0(
    "https://sec.report/Senate-Stock-Disclosures/",last_name,"/",first_name,"/",report_id
  )) %>%
  select(-a,-b,-c,-d,-shares_held) %>%
  rename(senator_full_name = reported_by,
         report_title=title,
         senator_first_name = first_name,
         senator_last_name = last_name) %>%
  select(filed_date,report_id, report_title, report_url, senator_full_name,senator_first_name,senator_last_name)

# Create a list of urls to loop through
filings_table_url_list <- filings_table %>%
  select(report_url) %>%
  # for testing
  #slice(1:90) %>%
  as_vector()

# create empty dataframe to hold results
senator_assets_all <- tibble()

# for debugging
report_url_value <- "https://sec.report/Senate-Stock-Disclosures/Romney/W+Mitt/580c4c34-031f-4dbc-89e3-52c84effb069"
#report_url_value <- "https://sec.report/Senate-Stock-Disclosures/Cassidy/William/50e02aba-3d11-42d9-b0fd-153fd1b21a8c"
for (report_url_value in filings_table_url_list) {
  
  # Filter senator table for each senator's row
  senator_table <- filings_table %>%
    filter(report_url == report_url_value)
  
  # Grab financial tables
  financial_tables <- report_url_value %>%
    read_html() %>%
    html_table()
  
  # Grab asset table
  
  assets_table <- tibble(
    data = financial_tables
  ) %>%
  filter(str_detect(data,"Asset Type")) %>%
  unnest() %>%
  clean_names() %>%
  select(-v1)
  
  # Bind asset table back to senator table
  senator_assets_table <- senator_table %>%
    bind_cols(assets_table)
  
  # Add senator_assets_table to master dataframe
  senator_assets_all <- senator_assets_all %>%
    bind_rows(senator_assets_table)

}

write_rds(senator_assets_all,"senate_assets.rds")

```

```{r}
x <- senator_assets_all %>%
  group_by(asset_type) %>%
  count() %>%
  arrange(desc(n))

businesses <- senator_assets_all %>%
  filter(str_detect(asset_type,"Receivable|Business"))


businesses
```

```{r}
# For loop, iterating over each row in our naics industry dataframe
for(row_number in 1:nrow(naics_industry)) {

    # Keep only the row for a given row number, get rid of every other row
    each_row_df <- naics_industry %>%
      slice(row_number)

    # Define url of page to get
    url <- each_row_df$sector_url

    # Define id of table to ingest
    xpath_employment_table <- paste0('//*[@id="',each_row_df$sector_xpath_id,'"]')

    # Get employment table from each page by going to each url defined above, reading in the html with read_html(), extracting the table with the id generated by the xpath code using html_elements), and then turning the html into a proper dataframe using html_table().  The dataframe is in a nested list, which we'll have to extract in the next step.
    employment_info <- url %>%
      read_html() %>%
      html_elements(xpath = xpath_employment_table) %>%
      html_table()

    # Grab the dataframe out of the list (it's the first and only element inside the list); clean up the field names with clean_names(); use slice(2) to keep only the second row; use bind_cols() to append the sector code and name to this table; turn jun_2021 column into a proper number, and rename it.  Then select only three columns we need.
    employment_info <- employment_info[[1]] %>%
      clean_names() %>%
      slice(2) %>%
      bind_cols(each_row_df) %>%
      mutate(jun_2021 = parse_number(jun_2021)) %>%
      rename(jun_2021_employees = jun_2021) %>%
      select(sector,description,jun_2021_employees)

    # To help us see what's happening as we build this, we're going to print the thing we're creating.  
    print(employment_info)


}

```

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
